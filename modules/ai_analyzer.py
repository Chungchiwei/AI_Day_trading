"""
AI åˆ†ææ¨¡çµ„ - ä½¿ç”¨ Perplexity.ai é€²è¡Œç•¶æ²–åˆ†æ
å„ªåŒ–ç‰ˆï¼šå¤šæ¨¡å‹ç­–ç•¥ã€åˆ†å±¤ä»»å‹™è™•ç†ã€æ¸›å°‘ Token æ¶ˆè€—
"""
import os
import requests
import json
import time
from typing import Optional, Dict, List, Literal
import pandas as pd
from modules.database import get_database
from dotenv import load_dotenv

load_dotenv()

PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")


class AIAnalyzer:
    """AI åˆ†æå™¨é¡åˆ¥ - æ”¯æ´å¤šæ¨¡å‹ç­–ç•¥"""
    
    # æ¨¡å‹é…ç½® - æ ¹æ“šä¸åŒä»»å‹™é¸æ“‡æœ€é©åˆçš„æ¨¡å‹
    MODEL_CONFIG = {
        'news_search': {
            'model': 'sonar',  # ç·šä¸Šæœå°‹æ¨¡å‹
            'max_tokens': 800,
            'temperature': 0.2,
            'description': 'æ–°èæœå°‹èˆ‡åˆç¯©',
            'use_search': True
        },
        'news_summary': {
            'model': 'sonar',  # å¿«é€Ÿæ‘˜è¦
            'max_tokens': 500,
            'temperature': 0.1,
            'description': 'æ–°èæ‘˜è¦èˆ‡çµæ§‹åŒ–',
            'use_search': False
        },
        'technical_analysis': {
            'model': 'sonar-reasoning',  # æ¨ç†æ¨¡å‹
            'max_tokens': 2500,  # âœ… å¢åŠ  token ä¸Šé™
            'temperature': 0.3,
            'description': 'æŠ€è¡“é¢åˆ†æ',
            'use_search': False
        },
        'comprehensive_analysis': {
            'model': 'sonar-pro',  # å°ˆæ¥­ç‰ˆ
            'max_tokens': 3500,  # âœ… å¢åŠ  token ä¸Šé™
            'temperature': 0.3,
            'description': 'ç¶œåˆåˆ†æèˆ‡æ±ºç­–',
            'use_search': False
        },
        'deep_research': {
            'model': 'sonar-research',  # æ·±åº¦ç ”ç©¶
            'max_tokens': 4000,  # âœ… å¢åŠ  token ä¸Šé™
            'temperature': 0.2,
            'description': 'æ·±åº¦ç ”ç©¶ï¼ˆé‡å¤§äº‹ä»¶ï¼‰',
            'use_search': True
        },
        'quick_analysis': {
            'model': 'sonar',  # å¿«é€Ÿåˆ†æ
            'max_tokens': 4000,
            'temperature': 0.3,
            'description': 'å¿«é€ŸæŠ€è¡“åˆ†æ',
            'use_search': False
        }
    }
    
    # æ–°èä¾†æºç™½åå–®ï¼ˆå°ç£ä¸»è¦è²¡ç¶“åª’é«”ï¼‰
    TRUSTED_DOMAINS = [
        'cnyes.com',           # é‰…äº¨ç¶²
        'money.udn.com',       # ç¶“æ¿Ÿæ—¥å ±
        'ctee.com.tw',         # å·¥å•†æ™‚å ±
        'wealth.com.tw',       # è²¡è¨Š
        'businessweekly.com.tw', # å•†æ¥­å‘¨åˆŠ
        'cw.com.tw',           # å¤©ä¸‹é›œèªŒ
        'mops.twse.com.tw',    # å…¬é–‹è³‡è¨Šè§€æ¸¬ç«™
        'twse.com.tw'          # è­‰äº¤æ‰€
    ]
    
    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨
        
        Args:
            api_key: Perplexity API Key
        """
        self.api_key = api_key or PERPLEXITY_API_KEY
        self.base_url = "https://api.perplexity.ai/chat/completions"
        self.db = get_database()
        
        if not self.api_key:
            print("âš ï¸ PERPLEXITY_API_KEY æœªè¨­å®š")
        
        # Token ä½¿ç”¨çµ±è¨ˆï¼ˆæŒ‰æ¨¡å‹åˆ†é¡ï¼‰
        self.token_usage = {
            'by_model': {},
            'total': {
                'prompt_tokens': 0,
                'completion_tokens': 0,
                'total_tokens': 0
            }
        }
    
    def search_news_events(self, symbol: str, force_update: bool = False, 
                          use_deep_research: bool = False) -> Dict:
        """
        ä½¿ç”¨ Perplexity.ai æœå°‹è‚¡ç¥¨è¿‘æœŸæ–°èäº‹ä»¶ï¼ˆæ”¯æ´å¿«å–ï¼‰
        å„ªåŒ–ç‰ˆï¼šåˆ†å…©éšæ®µè™•ç†ï¼ˆæœå°‹ â†’ æ‘˜è¦ï¼‰
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            force_update: æ˜¯å¦å¼·åˆ¶æ›´æ–°
            use_deep_research: æ˜¯å¦ä½¿ç”¨æ·±åº¦ç ”ç©¶æ¨¡å‹ï¼ˆé‡å¤§äº‹ä»¶æ™‚ä½¿ç”¨ï¼‰
        
        Returns:
            dict: åŒ…å«æ–°èå…§å®¹å’Œå…ƒæ•¸æ“šçš„å­—å…¸
        """
        try:
            # å˜—è©¦å¾å¿«å–è®€å–ï¼ˆ24å°æ™‚å…§æœ‰æ•ˆï¼‰
            if not force_update:
                cached_news = self.db.get_news_cache(symbol, max_age_hours=24)
                if cached_news:
                    print(f"âœ… å¾å¿«å–è®€å– {symbol} çš„æ–°è")
                    return {
                        'content': cached_news,
                        'is_fallback': False,
                        'source': 'cache',
                        'model': 'cache',
                        'timestamp': None
                    }
            
            print(f"ğŸ” éšæ®µ 1: æœå°‹ {symbol} çš„æ–°èäº‹ä»¶...")
            
            if not self.api_key:
                print("âš ï¸ æœªè¨­å®š PERPLEXITY_API_KEY")
                return self._get_fallback_news(symbol)
            
            # éšæ®µ 1: ä½¿ç”¨å°æ¨¡å‹æœå°‹å’Œåˆç¯©
            search_messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯å°è‚¡æ–°èæœå°‹åŠ©æ‰‹ã€‚è«‹æœå°‹ä¸¦åˆ—å‡ºæœ€é‡è¦çš„æ–°èæ¨™é¡Œå’Œä¾†æºï¼Œç”¨ç¹é«”ä¸­æ–‡ã€‚"
                },
                {
                    "role": "user",
                    "content": f"""æœå°‹å°è‚¡ {symbol} æœ€è¿‘ 7 å¤©çš„é‡è¦æ–°èï¼Œåªåˆ—å‡ºï¼š
1. æ¨™é¡Œ
2. æ—¥æœŸ
3. ä¾†æºç¶²ç«™
æ ¼å¼ï¼š- [æ—¥æœŸ] æ¨™é¡Œ (ä¾†æº)

åªåˆ—å‡ºæœ€é‡è¦çš„ 3-5 å‰‡ï¼Œä¸è¦è©³ç´°å…§å®¹ã€‚"""
                }
            ]
            
            # ä½¿ç”¨å°æ¨¡å‹ + åŸŸåéæ¿¾
            search_result = self._call_api(
                search_messages,
                task_type='news_search',
                search_domain_filter=self.TRUSTED_DOMAINS
            )
            
            if not search_result:
                return self._get_fallback_news(symbol)
            
            raw_news = search_result['content']
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é‡å¤§æ–°èï¼ˆé—œéµå­—åˆ¤æ–·ï¼‰
            important_keywords = ['è²¡å ±', 'ä½µè³¼', 'é‡è¨Š', 'æ³•èªª', 'å¢è³‡', 'æ¸›è³‡', 'åœç‰Œ', 'è‘£äº‹æœƒ']
            has_important_event = any(keyword in raw_news for keyword in important_keywords)
            
            # éšæ®µ 2: æ ¹æ“šé‡è¦æ€§é¸æ“‡æ¨¡å‹é€²è¡Œæ‘˜è¦
            print(f"ğŸ“ éšæ®µ 2: ç”Ÿæˆæ–°èæ‘˜è¦...")
            
            task_type = 'deep_research' if (use_deep_research and has_important_event) else 'news_summary'
            
            if has_important_event:
                print(f"   âš ï¸ åµæ¸¬åˆ°é‡å¤§äº‹ä»¶ï¼Œä½¿ç”¨{'æ·±åº¦ç ”ç©¶' if use_deep_research else 'æ¨™æº–'}æ¨¡å‹")
            
            summary_messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯å°è‚¡æ–°èåˆ†æå°ˆå®¶ã€‚è«‹å°‡æ–°èæ•´ç†æˆçµæ§‹åŒ–æ ¼å¼ï¼Œç”¨ç¹é«”ä¸­æ–‡ã€‚"
                },
                {
                    "role": "user",
                    "content": f"""è«‹å°‡ä»¥ä¸‹ {symbol} çš„æ–°èæ•´ç†æˆï¼š

{raw_news}

---
è¼¸å‡ºæ ¼å¼ï¼š

## ğŸ“° é‡è¦æ–°è ({symbol})

### [æ—¥æœŸ] æ¨™é¡Œ
- **é¡å‹**: è²¡å ±/ä½µè³¼/ç”¢æ¥­/å…¶ä»–
- **å½±éŸ¿**: æ­£é¢/è² é¢/ä¸­æ€§
- **é‡é»**: ä¸€å¥è©±èªªæ˜

---
åªä¿ç•™æœ€é‡è¦çš„ 2-3 å‰‡ï¼Œæ¯å‰‡ä¸è¶…é 50 å­—ã€‚"""
                }
            ]
            
            summary_result = self._call_api(
                summary_messages,
                task_type=task_type
            )
            
            if summary_result:
                news_content = summary_result['content']
                
                # å„²å­˜åˆ°å¿«å–
                self.db.save_news_cache(symbol, news_content)
                
                print(f"âœ… æ–°èåˆ†æå®Œæˆ (ä½¿ç”¨æ¨¡å‹: {summary_result['model']})")
                
                return {
                    'content': news_content,
                    'is_fallback': False,
                    'source': 'api',
                    'model': summary_result['model'],
                    'has_important_event': has_important_event,
                    'timestamp': time.time()
                }
            else:
                return self._get_fallback_news(symbol)
            
        except Exception as e:
            print(f"âŒ æœå°‹æ–°èäº‹ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return self._get_fallback_news(symbol)
    
    def generate_daytrading_analysis(
        self,
        symbol: str,
        stock_data: pd.DataFrame,
        today_open: float,
        yesterday_close: float,
        support_resistance: Dict,
        institutional_data: Optional[pd.DataFrame] = None,
        news_events: Optional[Dict] = None,
        analysis_mode: str = 'comprehensive',  # 'quick', 'comprehensive', 'deep'
        **kwargs
    ) -> str:
        """
        ä½¿ç”¨ Perplexity.ai ç”Ÿæˆå®Œæ•´çš„ç•¶æ²–æ±ºç­–åˆ†æ
        å„ªåŒ–ç‰ˆï¼šæ ¹æ“šæ¨¡å¼é¸æ“‡æ¨¡å‹ã€ç²¾ç°¡æç¤ºè©
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç¢¼
            stock_data: åŒ…å«æŠ€è¡“æŒ‡æ¨™çš„æ­·å²åƒ¹æ ¼æ•¸æ“š (DataFrame)
            today_open: ç•¶æ—¥é–‹ç›¤åƒ¹
            yesterday_close: æ˜¨æ—¥æ”¶ç›¤åƒ¹
            support_resistance: æ”¯æ’å£“åŠ›ä½å­—å…¸
            institutional_data: ç±Œç¢¼æ•¸æ“š (å¯é¸)
            news_events: æ–°èäº‹ä»¶å­—å…¸ (å¯é¸)
            analysis_mode: åˆ†ææ¨¡å¼ ('quick'/'comprehensive'/'deep')
            **kwargs: å…¶ä»–åƒæ•¸
        
        Returns:
            str: AI ç”Ÿæˆçš„ç•¶æ²–åˆ†æå ±å‘Š
        """
        try:
            if not self.api_key:
                return self._get_no_api_key_message()
            
            # å¾ kwargs å–å¾—åƒæ•¸
            fee_discount = kwargs.get('fee_discount', 2.8)
            tax_rate = kwargs.get('tax_rate', 0.15)
            total_capital = kwargs.get('total_capital', 100000)
            risk_percent = kwargs.get('risk_percent', 1.0)
            
            # æº–å‚™åˆ†ææ•¸æ“šï¼ˆç²¾ç°¡ç‰ˆï¼‰
            analysis_data = self._prepare_analysis_data_compact(
                symbol, stock_data, today_open, yesterday_close,
                support_resistance, institutional_data, news_events
            )
            
            # é¸æ“‡æ¨¡å‹
            model_key = self._select_analysis_model(analysis_mode, news_events)
            model_config = self.MODEL_CONFIG[model_key]
            
            print(f"ğŸ¤– ä½¿ç”¨ {model_config['model']} ç”Ÿæˆåˆ†æ...")
            print(f"   ğŸ“‹ ä»»å‹™: {model_config['description']}")
            print(f"   ğŸ¯ æ¨¡å¼: {analysis_mode}")
            
            # æ§‹å»ºæç¤ºèªï¼ˆæ ¹æ“šæ¨¡å¼èª¿æ•´è©³ç´°ç¨‹åº¦ï¼‰
            system_message, user_prompt = self._build_prompts_compact(
                analysis_data, fee_discount, tax_rate, total_capital, 
                risk_percent, analysis_mode
            )
            
            messages = [
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_prompt}
            ]
            
            # èª¿ç”¨ API
            result = self._call_api(messages, task_type=model_key)
            
            if result:
                analysis = result['content']
                
                # æ·»åŠ æ¨™ç±¤
                header = self._get_analysis_header(analysis_mode, analysis_data['has_news'], model_config)
                footer = self._get_token_info()
                
                print(f"âœ… åˆ†æå®Œæˆ (ç¸½ Token: {self.token_usage['total']['total_tokens']})")
                
                return f"{header}{analysis}\n\n{footer}"
            else:
                return self._get_fallback_analysis(
                    symbol, today_open, yesterday_close,
                    stock_data.iloc[-1] if not stock_data.empty else {}
                )
            
        except Exception as e:
            print(f"âŒ AI åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            import traceback
            print(traceback.format_exc())
            
            return self._get_error_message(str(e))
    
    def _select_analysis_model(self, analysis_mode: str, news_events: Optional[Dict]) -> str:
        """
        æ ¹æ“šåˆ†ææ¨¡å¼å’Œæ–°èæƒ…æ³é¸æ“‡æœ€é©åˆçš„æ¨¡å‹
        
        Args:
            analysis_mode: åˆ†ææ¨¡å¼
            news_events: æ–°èäº‹ä»¶
        
        Returns:
            str: æ¨¡å‹é…ç½®éµå€¼
        """
        has_news = news_events is not None and not news_events.get('is_fallback', True)
        
        if analysis_mode == 'deep':
            return 'deep_research'
        elif analysis_mode == 'quick':
            return 'quick_analysis' if not has_news else 'technical_analysis'
        else:  # comprehensive
            if has_news:
                return 'comprehensive_analysis'
            else:
                return 'technical_analysis'
    
    def _prepare_analysis_data_compact(
        self, symbol, stock_data, today_open, yesterday_close,
        support_resistance, institutional_data, news_events
    ) -> Dict:
        """æº–å‚™åˆ†ææ‰€éœ€çš„æ•¸æ“šï¼ˆç²¾ç°¡ç‰ˆï¼‰"""
        
        # è¨ˆç®—ç¼ºå£
        gap_amount = today_open - yesterday_close
        gap_percent = (gap_amount / yesterday_close) * 100
        gap_direction = "å‘ä¸Š" if gap_amount > 0 else "å‘ä¸‹"
        
        # æœ€æ–°æŠ€è¡“æŒ‡æ¨™ï¼ˆåªä¿ç•™é—œéµæŒ‡æ¨™ï¼‰
        latest = stock_data.iloc[-1] if not stock_data.empty else {}
        
        key_indicators = {
            'close': float(latest.get('close', 0)),
            'MA5': float(latest.get('MA5', 0)),
            'MA20': float(latest.get('MA20', 0)),
            'MA60': float(latest.get('MA60', 0)),
            'RSI': float(latest.get('RSI', 0)),
            'MACD': float(latest.get('MACD', 0)),
            'MACD_signal': float(latest.get('MACD_signal', 0)),
            'KD_K': float(latest.get('KD_K', 0)),
            'KD_D': float(latest.get('KD_D', 0)),
            'BB_upper': float(latest.get('BB_upper', 0)),
            'BB_middle': float(latest.get('BB_middle', 0)),
            'BB_lower': float(latest.get('BB_lower', 0)),
            'volume': float(latest.get('volume', 0))
        }
        
        # è¨ˆç®—é‡æ¯”
        if not stock_data.empty and stock_data['volume'].mean() > 0:
            key_indicators['volume_ratio'] = key_indicators['volume'] / stock_data['volume'].mean()
        else:
            key_indicators['volume_ratio'] = 1.0
        
        # æ”¯æ’å£“åŠ›ä½ï¼ˆåªå–æœ€è¿‘çš„ 2 å€‹ï¼‰
        resistance_list = support_resistance.get('resistance', [])[:2]
        support_list = support_resistance.get('support', [])[:2]
        
        # ç±Œç¢¼æ•¸æ“šï¼ˆç²¾ç°¡ç‰ˆï¼‰
        institutional_summary = ""
        if institutional_data is not None and not institutional_data.empty:
            latest_inst = institutional_data.iloc[-1]
            foreign = float(latest_inst.get('Foreign_Investor', 0))
            trust = float(latest_inst.get('Investment_Trust', 0))
            dealer = float(latest_inst.get('Dealer', 0))
            
            # åªå ±å‘Šé‡è¦çš„ç±Œç¢¼å‹•å‘
            if abs(foreign) > 1000 or abs(trust) > 500:
                institutional_summary = f"å¤–è³‡ {foreign:+,.0f}å¼µ, æŠ•ä¿¡ {trust:+,.0f}å¼µ, è‡ªç‡Ÿ {dealer:+,.0f}å¼µ"
        
        # æ–°èæ•¸æ“šï¼ˆç²¾ç°¡ç‰ˆï¼‰
        news_content = None
        has_news = False
        news_model = None
        has_important_event = False
        
        if news_events is not None:
            news_content_full = news_events.get('content', '')
            has_news = not news_events.get('is_fallback', True)
            news_model = news_events.get('model', 'unknown')
            has_important_event = news_events.get('has_important_event', False)
            
            # åªå–æ–°èçš„å‰ 300 å­—ï¼ˆæ¸›å°‘ Tokenï¼‰
            if has_news and news_content_full:
                news_content = news_content_full[:300] + "..." if len(news_content_full) > 300 else news_content_full
        
        return {
            'symbol': symbol,
            'yesterday_close': yesterday_close,
            'today_open': today_open,
            'gap_direction': gap_direction,
            'gap_percent': gap_percent,
            'key_indicators': key_indicators,
            'resistance_list': resistance_list,
            'support_list': support_list,
            'institutional_summary': institutional_summary,
            'news_content': news_content,
            'has_news': has_news,
            'news_model': news_model,
            'has_important_event': has_important_event
        }
    
    def _build_prompts_compact(self, data: Dict, fee_discount, tax_rate, 
                              total_capital, risk_percent, analysis_mode: str) -> tuple:
        """æ§‹å»ºç³»çµ±æç¤ºå’Œç”¨æˆ¶æç¤ºï¼ˆç²¾ç°¡ç‰ˆï¼‰"""
        
        # ç³»çµ±æç¤º
        if analysis_mode == 'deep':
            system_message = """ä½ æ˜¯å°è‚¡ç•¶æ²–åˆ†æå°ˆå®¶ã€‚è«‹é€²è¡Œæ·±åº¦åˆ†æï¼ŒåŒ…å«å¤šæ™‚é–“æ¡†æ¶æŠ€è¡“åˆ†æã€æ·±å…¥ç±Œç¢¼è§£è®€ã€æ–°èå½±éŸ¿è©•ä¼°ã€é¢¨éšªæƒ…å¢ƒæ¨¡æ“¬ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œæ ¼å¼æ¸…æ™°ã€‚"""
        elif analysis_mode == 'quick':
            system_message = """ä½ æ˜¯å°è‚¡ç•¶æ²–åˆ†æå°ˆå®¶ã€‚è«‹æä¾›å¿«é€Ÿä½†æº–ç¢ºçš„åˆ†æï¼šç•¶æ—¥é©åˆåº¦ã€é—œéµåƒ¹ä½ã€ä¸»è¦é¢¨éšªã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œç°¡æ½”æ˜ç¢ºã€‚"""
        else:  # comprehensive
            system_message = """ä½ æ˜¯å°è‚¡ç•¶æ²–åˆ†æå°ˆå®¶ã€‚è«‹åŸºæ–¼æŠ€è¡“ã€ç±Œç¢¼"""
            if data['has_news']:
                system_message += "ã€æ–°è"
            system_message += """æ•¸æ“šï¼Œæä¾›å°ˆæ¥­ç•¶æ²–å»ºè­°ã€‚æ˜ç¢ºçµ¦å‡ºé©åˆåº¦ã€é€²å‡ºå ´åƒ¹ã€éƒ¨ä½å¤§å°ã€é¢¨éšªæç¤ºã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¿æŒå®¢è§€ã€‚"""
        
        # ç”¨æˆ¶æç¤ºï¼ˆæ ¹æ“šæ¨¡å¼èª¿æ•´ï¼‰
        if analysis_mode == 'quick':
            user_prompt = self._build_quick_prompt(data, fee_discount, tax_rate, total_capital, risk_percent)
        else:
            user_prompt = self._build_comprehensive_prompt(data, fee_discount, tax_rate, total_capital, risk_percent, analysis_mode)
        
        return system_message, user_prompt
    
    def _build_quick_prompt(self, data: Dict, fee_discount, tax_rate, total_capital, risk_percent) -> str:
        """æ§‹å»ºå¿«é€Ÿåˆ†ææç¤ºï¼ˆç²¾ç°¡ç‰ˆï¼‰"""
        
        ind = data['key_indicators']
        
        # æ ¼å¼åŒ–å£“åŠ›æ”¯æ’
        resistance_text = " / ".join([f"NT$ {r['price']:.2f}" for r in data['resistance_list']])
        support_text = " / ".join([f"NT$ {s['price']:.2f}" for s in data['support_list']])
        
        prompt = f"""## å¿«é€Ÿç•¶æ²–åˆ†æ - {data['symbol']}

**åƒ¹æ ¼**: æ˜¨æ”¶ {data['yesterday_close']:.2f} â†’ ä»Šé–‹ {data['today_open']:.2f} ({data['gap_percent']:+.2f}%)

**æŠ€è¡“**: RSI {ind['RSI']:.0f}, MACD {ind['MACD']:.2f}, KD {ind['KD_K']:.0f}
MA5 {ind['MA5']:.2f} / MA20 {ind['MA20']:.2f}

**é—œéµåƒ¹ä½**: 
å£“åŠ› {resistance_text} | æ”¯æ’ {support_text}
"""

        if data['institutional_summary']:
            prompt += f"\n**ç±Œç¢¼**: {data['institutional_summary']}"
        
        if data['has_news'] and data['news_content']:
            prompt += f"\n\n**æ–°è**: {data['news_content']}"
        
        prompt += f"""

**åƒæ•¸**: è³‡é‡‘ {total_capital:,}, é¢¨éšª {risk_percent}%, æ‰‹çºŒè²» {fee_discount}æŠ˜

---
è«‹æä¾›ï¼ˆç°¡æ½”ç‰ˆï¼‰ï¼š
1. é©åˆåº¦: âœ…é©åˆ / âš ï¸è¬¹æ… / âŒä¸å»ºè­°
2. é€²å ´åƒ¹: NT$ [åƒ¹æ ¼]
3. åœåˆ©åƒ¹: NT$ [åƒ¹æ ¼] (+X%)
4. åœæåƒ¹: NT$ [åƒ¹æ ¼] (-X%)
5. å»ºè­°å¼µæ•¸: [æ•¸å­—]å¼µ
6. é¢¨éšªæç¤º: [ä¸€å¥è©±]

è«‹ç›´æ¥çµ¦æ•¸å­—ï¼Œä¸è¦å†—é•·èªªæ˜ã€‚"""

        return prompt
    
    def _build_comprehensive_prompt(self, data: Dict, fee_discount, tax_rate, 
                                   total_capital, risk_percent, analysis_mode: str) -> str:
        """æ§‹å»ºå®Œæ•´åˆ†ææç¤ºï¼ˆâœ… ä¿®æ”¹ç‚ºæ›´è©³ç´°çš„æ“ä½œæŒ‡å¼•ï¼‰"""
        
        ind = data['key_indicators']
        
        # âœ… è¨ˆç®—æœ€å¤§å¯æ‰¿å—æå¤±
        max_loss = int(total_capital * risk_percent / 100)
        
        # âœ… è¨ˆç®—äº¤æ˜“æˆæœ¬ç‡
        cost_rate = (0.1425 * fee_discount / 10 + tax_rate / 100)
        
        prompt = f"""ä½ æ˜¯å°ˆæ¥­çš„å°è‚¡ç•¶æ²–äº¤æ˜“åˆ†æå¸«ï¼Œè«‹é‡å° {data['symbol']} æä¾›å®Œæ•´çš„ç•¶æ²–æ“ä½œå»ºè­°ã€‚

## ğŸ“Š å¸‚å ´æ•¸æ“š

### åƒ¹æ ¼è³‡è¨Š
- æ˜¨æ—¥æ”¶ç›¤ï¼šNT$ {data['yesterday_close']:.2f}
- ä»Šæ—¥é–‹ç›¤ï¼šNT$ {data['today_open']:.2f}
- é–‹ç›¤ç¼ºå£ï¼š{data['gap_direction']} {abs(data['gap_percent']):.2f}%

### æŠ€è¡“æŒ‡æ¨™
- **RSI(14)**: {ind['RSI']:.2f} {'(è¶…è²·å€)' if ind['RSI'] > 70 else '(è¶…è³£å€)' if ind['RSI'] < 30 else '(ä¸­æ€§å€)'}
- **MACD**: {ind['MACD']:.4f} | Signal: {ind['MACD_signal']:.4f} | å·®é›¢å€¼: {(ind['MACD']-ind['MACD_signal']):.4f}
- **KD æŒ‡æ¨™**: K={ind['KD_K']:.2f}, D={ind['KD_D']:.2f}
- **ç§»å‹•å¹³å‡ç·š**: MA5 {ind['MA5']:.2f} / MA20 {ind['MA20']:.2f} / MA60 {ind['MA60']:.2f}
- **å¸ƒæ—é€šé“**: ä¸Šè»Œ {ind['BB_upper']:.2f} / ä¸­è»Œ {ind['BB_middle']:.2f} / ä¸‹è»Œ {ind['BB_lower']:.2f}
- **æˆäº¤é‡æ¯”**: {ind['volume_ratio']:.2f}x {'(çˆ†é‡)' if ind['volume_ratio'] > 2 else '(æ”¾é‡)' if ind['volume_ratio'] > 1.5 else '(ç¸®é‡)' if ind['volume_ratio'] < 0.7 else '(æ­£å¸¸)'}

### é—œéµåƒ¹ä½
"""
        
        # å£“åŠ›ä½
        if data['resistance_list']:
            prompt += "**å£“åŠ›ä½ï¼ˆè³£å‡ºåƒè€ƒï¼‰**:\n"
            for i, r in enumerate(data['resistance_list'], 1):
                prompt += f"{i}. NT$ {r['price']:.2f} - {r['desc']}\n"
        
        # æ”¯æ’ä½
        if data['support_list']:
            prompt += "\n**æ”¯æ’ä½ï¼ˆè²·é€²åƒè€ƒï¼‰**:\n"
            for i, s in enumerate(data['support_list'], 1):
                prompt += f"{i}. NT$ {s['price']:.2f} - {s['desc']}\n"
        
        # ç±Œç¢¼æ•¸æ“š
        if data['institutional_summary']:
            prompt += f"\n### ä¸‰å¤§æ³•äººç±Œç¢¼\n{data['institutional_summary']}\n"
        
        # æ–°èæ•¸æ“š
        if data['has_news'] and data['news_content']:
            prompt += f"\n### è¿‘æœŸæ–°è\n{data['news_content']}\n"
        
        # äº¤æ˜“åƒæ•¸
        prompt += f"""
## ğŸ’¼ äº¤æ˜“åƒæ•¸è¨­å®š
- **å¯ç”¨è³‡é‡‘**: NT$ {total_capital:,}
- **å–®ç­†é¢¨éšªæ¯”ä¾‹**: {risk_percent}%
- **æœ€å¤§å¯æ‰¿å—æå¤±**: NT$ {max_loss:,}
- **æ‰‹çºŒè²»æŠ˜æ‰£**: {fee_discount} æŠ˜
- **è­‰äº¤ç¨…ç‡**: {tax_rate}%
- **å–®è¶Ÿäº¤æ˜“æˆæœ¬**: ç´„ {cost_rate:.4f}%

---

## ğŸ¯ è«‹ä½ ä½œç‚ºå°ˆæ¥­ç•¶æ²–åˆ†æå¸«ï¼Œæä¾›ä»¥ä¸‹å®Œæ•´çš„æ“ä½œå»ºè­°ï¼š

### 1ï¸âƒ£ ç•¶æ²–é©åˆåº¦è©•ä¼°ï¼ˆå¿…ç­”ï¼‰

è«‹ç¶œåˆä»¥ä¸Šæ‰€æœ‰æ•¸æ“šï¼ˆæŠ€è¡“é¢ã€ç±Œç¢¼é¢{'ã€æ–°èé¢' if data['has_news'] else ''}ï¼‰ï¼Œæ˜ç¢ºåˆ¤æ–·ï¼Œç›´æ¥å‘Šè¨´æˆ‘èƒ½ä¸èƒ½è³¼è²·ï¼Œå»ºè­°è³¼è²·å¼µæ•¸ï¼š


**é©åˆåº¦åˆ¤æ–·**ï¼š
- âœ… **é©åˆç•¶æ²–** - èªªæ˜ç‚ºä»€éº¼é©åˆï¼ˆä¾‹å¦‚ï¼šæŠ€è¡“æŒ‡æ¨™å¤šé ­ã€é‡èƒ½æ”¾å¤§ã€æ³•äººè²·è¶…ï¼‰
- âš ï¸ **è¬¹æ…æ“ä½œ** - èªªæ˜é¢¨éšªå› ç´ ï¼ˆä¾‹å¦‚ï¼šæŠ€è¡“æŒ‡æ¨™çŸ›ç›¾ã€é‡èƒ½ä¸è¶³ï¼‰
- âŒ **ä¸å»ºè­°ç•¶æ²–** - èªªæ˜ç‚ºä»€éº¼ä¸é©åˆï¼ˆä¾‹å¦‚ï¼šç©ºé ­æ’åˆ—ã€æ³•äººå¤§è³£ã€é‡å¤§åˆ©ç©ºï¼‰

**ä¿¡å¿ƒæŒ‡æ•¸**ï¼š[1-10åˆ†] ï¼ˆ1=å®Œå…¨ä¸å»ºè­°ï¼Œ10=å¼·çƒˆå»ºè­°ï¼‰

---

### 2ï¸âƒ£ é€²å ´ç­–ç•¥ï¼ˆå¦‚æœé©åˆç•¶æ²–ï¼Œè«‹æä¾›å…·é«”å»ºè­°ï¼‰

#### ğŸ“ é€²å ´åƒ¹ä½
- **æœ€ä½³é€²å ´åƒ¹**: NT$ [å…·é«”åƒ¹æ ¼]
  - **ç†ç”±**: [èªªæ˜ç‚ºä»€éº¼é¸é€™å€‹åƒ¹ä½ï¼Œä¾‹å¦‚ï¼šçªç ´å£“åŠ›ã€å›æ¸¬æ”¯æ’ã€æŠ€è¡“æŒ‡æ¨™è½‰å¼·]
  - **é€²å ´æ™‚æ©Ÿ**: [é–‹ç›¤å¾Œå¹¾åˆ†é˜ï¼Ÿç­‰å¾…ä»€éº¼è¨Šè™Ÿï¼Ÿ]

- **æ¬¡ä½³é€²å ´åƒ¹**: NT$ [å…·é«”åƒ¹æ ¼]ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
  - **ç†ç”±**: [èªªæ˜]

#### ğŸ’° éƒ¨ä½è¦åŠƒ
æ ¹æ“šè³‡é‡‘ NT$ {total_capital:,} å’Œé¢¨éšª {risk_percent}%ï¼š
- **å»ºè­°è²·é€²å¼µæ•¸**: [å…·é«”å¼µæ•¸]
- **é è¨ˆæŠ•å…¥è³‡é‡‘**: NT$ [é‡‘é¡]
- **ä¿ç•™è³‡é‡‘**: NT$ [é‡‘é¡]
- **æ¯å¼µæˆæœ¬**: NT$ [é‡‘é¡]ï¼ˆå«æ‰‹çºŒè²»ï¼‰

---

### 3ï¸âƒ£ åœåˆ©ç­–ç•¥ï¼ˆç²åˆ©å‡ºå ´ï¼Œè«‹çµ¦å…·é«”åƒ¹æ ¼ï¼‰

| åœåˆ©é» | åƒ¹æ ¼ | ç²åˆ©% | å‡ºå ´æ¯”ä¾‹ | é æœŸç²åˆ© |
|--------|------|-------|----------|----------|
| ç¬¬ä¸€åœåˆ© | NT$ [åƒ¹æ ¼] | +[X]% | [X]% | NT$ [é‡‘é¡] |
| ç¬¬äºŒåœåˆ© | NT$ [åƒ¹æ ¼] | +[X]% | [X]% | NT$ [é‡‘é¡] |
| çµ‚æ¥µåœåˆ© | NT$ [åƒ¹æ ¼] | +[X]% | 100% | NT$ [é‡‘é¡] |

**åœåˆ©ç­–ç•¥èªªæ˜**ï¼š
- ç¬¬ä¸€åœåˆ©ï¼š[èªªæ˜è§¸ç™¼æ¢ä»¶ï¼Œä¾‹å¦‚ï¼šçªç ´å£“åŠ›ã€æŠ€è¡“æŒ‡æ¨™éç†±]
- ç¬¬äºŒåœåˆ©ï¼š[èªªæ˜]
- çµ‚æ¥µåœåˆ©ï¼š[èªªæ˜]

**ç¸½é æœŸç²åˆ©**ï¼šNT$ [é‡‘é¡]ï¼ˆæ‰£é™¤äº¤æ˜“æˆæœ¬å¾Œï¼‰

---

### 4ï¸âƒ£ åœæç­–ç•¥ï¼ˆé¢¨éšªæ§åˆ¶ï¼Œè«‹çµ¦å…·é«”åƒ¹æ ¼ï¼‰

| åœæé» | åƒ¹æ ¼ | è™§æ% | åœæé‡‘é¡ | è§¸ç™¼æ¢ä»¶ |
|--------|------|-------|----------|----------|
| ç¬¬ä¸€åœæ | NT$ [åƒ¹æ ¼] | -[X]% | NT$ [é‡‘é¡] | [æ¢ä»¶] |
| å¼·åˆ¶åœæ | NT$ [åƒ¹æ ¼] | -[X]% | NT$ [é‡‘é¡] | ç„¡æ¢ä»¶å‡ºå ´ |

**åœæç­–ç•¥èªªæ˜**ï¼š
- **ç¬¬ä¸€åœæé»**: [èªªæ˜è§¸ç™¼æ¢ä»¶ï¼Œä¾‹å¦‚ï¼šè·Œç ´æ”¯æ’ã€æŠ€è¡“æŒ‡æ¨™è½‰å¼±ã€é‡èƒ½ç•°å¸¸]
- **å¼·åˆ¶åœæé»**: [èªªæ˜ï¼Œå¿…é ˆåš´æ ¼åŸ·è¡Œï¼Œä¸å¯çŒ¶è±«]
- **æœ€å¤§æå¤±**: NT$ [é‡‘é¡]ï¼ˆä¸è¶…éé¢¨éšªæ¯”ä¾‹ {risk_percent}%ï¼‰

**é‡è¦æé†’**ï¼šåœææ˜¯ä¿å‘½ç¬¦ï¼Œçµ•å°ä¸å¯å¿ƒå­˜åƒ¥å€–ï¼

---

### 5ï¸âƒ£ ç›¤ä¸­ç›£æ§é‡é»ï¼ˆè«‹å‘Šè¨´æˆ‘ç›¤ä¸­è¦æ³¨æ„ä»€éº¼ï¼‰

#### ğŸ” é—œéµåƒ¹ä½ç›£æ§
åˆ—å‡º 3-5 å€‹é—œéµåƒ¹æ ¼ï¼š
1. NT$ [åƒ¹æ ¼] - [èªªæ˜æ„ç¾©]
2. NT$ [åƒ¹æ ¼] - [èªªæ˜æ„ç¾©]
3. NT$ [åƒ¹æ ¼] - [èªªæ˜æ„ç¾©]

#### ğŸ“Š é‡èƒ½è®ŠåŒ–
- **åŠ ç¢¼è¨Šè™Ÿ**: [ä»€éº¼æƒ…æ³ä¸‹å¯ä»¥åŠ ç¢¼ï¼Ÿ]
- **æ¸›ç¢¼è¨Šè™Ÿ**: [ä»€éº¼æƒ…æ³ä¸‹è¦æ¸›ç¢¼ï¼Ÿ]
- **å‡ºå ´è¨Šè™Ÿ**: [ä»€éº¼æƒ…æ³ä¸‹è¦ç«‹å³å‡ºå ´ï¼Ÿ]

#### â° æ™‚é–“é»æ“ä½œ
- **é–‹ç›¤ï¼ˆ9:00-9:30ï¼‰**: [è¦æ³¨æ„ä»€éº¼ï¼Ÿ]
- **æ—©ç›¤ï¼ˆ9:30-11:00ï¼‰**: [è¦æ³¨æ„ä»€éº¼ï¼Ÿ]
- **åˆç›¤ï¼ˆ11:00-13:00ï¼‰**: [è¦æ³¨æ„ä»€éº¼ï¼Ÿ]
- **å°¾ç›¤ï¼ˆ13:00-13:30ï¼‰**: [è¦æ³¨æ„ä»€éº¼ï¼Ÿ]

---

### 6ï¸âƒ£ é¢¨éšªæç¤ºèˆ‡æ‡‰è®Šæ–¹æ¡ˆ

#### âš ï¸ ä¸»è¦é¢¨éšª
åˆ—å‡º 2-3 å€‹æœ€å¤§é¢¨éšªï¼š
1. [é¢¨éšª 1] - [èªªæ˜]
2. [é¢¨éšª 2] - [èªªæ˜]
3. [é¢¨éšª 3] - [èªªæ˜]

#### ğŸ”„ æ‡‰è®Šæ–¹æ¡ˆ
- **å¦‚æœé–‹ç›¤ä¸å¦‚é æœŸ**ï¼ˆä¾‹å¦‚ï¼šè·³ç©ºé–‹ä½ã€é–‹é«˜èµ°ä½ï¼‰ï¼š
  - [è©²æ€éº¼è¾¦ï¼Ÿ]

- **å¦‚æœç›¤ä¸­å‡ºç¾æ„å¤–**ï¼ˆä¾‹å¦‚ï¼šçªç„¶çˆ†é‡ã€æ€¥æ®ºã€é‡å¤§æ¶ˆæ¯ï¼‰ï¼š
  - [è©²æ€éº¼æ‡‰å°ï¼Ÿ]

- **å¦‚æœä¸é©åˆç•¶æ²–**ï¼š
  - [æœ‰æ²’æœ‰å…¶ä»–å»ºè­°ï¼Ÿä¾‹å¦‚ï¼šç­‰å¾…æ›´å¥½æ™‚æ©Ÿã€æ”¹åšæ³¢æ®µ]

---

### 7ï¸âƒ£ ç¸½çµå»ºè­°ï¼ˆç”¨ä¸€æ®µè©±ç¸½çµï¼‰

è«‹å›ç­”ä»¥ä¸‹å•é¡Œï¼š
1. **ä»Šå¤©é€™æ”¯è‚¡ç¥¨é©ä¸é©åˆç•¶æ²–ï¼Ÿ** [æ˜¯/å¦ï¼Œç†ç”±]
2. **å¦‚æœè¦åšï¼Œæœ€é‡è¦çš„æ“ä½œé‡é»æ˜¯ä»€éº¼ï¼Ÿ** [ä¸€å¥è©±]
3. **æœ€å¤§çš„é¢¨éšªæ˜¯ä»€éº¼ï¼Ÿ** [ä¸€å¥è©±]
4. **ä½ çš„ä¿¡å¿ƒæŒ‡æ•¸æ˜¯å¤šå°‘ï¼Ÿ** [1-10åˆ†]

---

## âš ï¸ é‡è¦æé†’

1. **è«‹çµ¦å‡ºå…·é«”çš„æ•¸å­—å’Œåƒ¹æ ¼**ï¼Œä¸è¦æ¨¡ç³Šçš„èªªæ³•ï¼ˆä¾‹å¦‚ï¼šã€Œé©ç•¶åƒ¹ä½ã€ã€ã€Œåˆç†ç¯„åœã€ï¼‰
2. **åœæé»å¿…é ˆåš´æ ¼**ï¼Œä¸å¯å¿ƒå­˜åƒ¥å€–
3. **ç•¶æ²–äº¤æ˜“é¢¨éšªæ¥µé«˜**ï¼Œè«‹å‹™å¿…è¬¹æ…è©•ä¼°
4. **å¦‚æœæŠ€è¡“é¢ã€ç±Œç¢¼é¢{'ã€æ–°èé¢' if data['has_news'] else ''}æœ‰çŸ›ç›¾**ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºä¸¦å»ºè­°è¬¹æ…æˆ–æ”¾æ£„

è«‹ç¾åœ¨é–‹å§‹ä½ çš„å®Œæ•´åˆ†æï¼Œè¨˜å¾—è¦çµ¦å‡º**å…·é«”çš„æ•¸å­—ã€åƒ¹æ ¼ã€å¼µæ•¸ã€é‡‘é¡**ï¼
"""
        
        return prompt
    
    def _call_api(self, messages: List[Dict], task_type: str = 'technical_analysis',
                  search_domain_filter: Optional[List[str]] = None,
                  max_retries: int = 2) -> Optional[Dict]:
        """
        å‘¼å« Perplexity APIï¼ˆå„ªåŒ–ç‰ˆï¼Œæ”¯æ´ä»»å‹™åˆ†å±¤ï¼‰
        
        Args:
            messages: å°è©±è¨Šæ¯åˆ—è¡¨
            task_type: ä»»å‹™é¡å‹ï¼ˆæ±ºå®šä½¿ç”¨å“ªå€‹æ¨¡å‹ï¼‰
            search_domain_filter: æœå°‹åŸŸåéæ¿¾å™¨
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
            
        Returns:
            åŒ…å«å›æ‡‰å’Œ token ä½¿ç”¨é‡çš„å­—å…¸
        """
        # ç²å–æ¨¡å‹é…ç½®
        config = self.MODEL_CONFIG.get(task_type, self.MODEL_CONFIG['technical_analysis'])
        model_name = config['model']
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": model_name,
            "messages": messages,
            "temperature": config['temperature'],
            "max_tokens": config['max_tokens']
        }
        
        # æ·»åŠ æœå°‹åŸŸåéæ¿¾ï¼ˆåƒ…é™æœ‰æœå°‹åŠŸèƒ½çš„æ¨¡å‹ï¼‰
        if search_domain_filter and config.get('use_search', False):
            payload['search_domain_filter'] = search_domain_filter
        
        for attempt in range(max_retries):
            try:
                print(f"   ğŸ“¡ API è«‹æ±‚ [{config['description']}] (å˜—è©¦ {attempt + 1}/{max_retries})")
                print(f"   ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
                
                response = requests.post(
                    self.base_url,
                    headers=headers,
                    json=payload,
                    timeout=120
                )
                
                # è™•ç† HTTP éŒ¯èª¤
                if response.status_code == 401:
                    print("   âŒ API Key èªè­‰å¤±æ•—")
                    return None
                elif response.status_code == 429:
                    print("   âš ï¸ è¶…éè«‹æ±‚é™åˆ¶")
                    if attempt < max_retries - 1:
                        wait_time = 10 * (attempt + 1)
                        print(f"   ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                        time.sleep(wait_time)
                        continue
                    return None
                
                response.raise_for_status()
                
                result = response.json()
                
                # è¨˜éŒ„ Token ä½¿ç”¨é‡ï¼ˆæŒ‰æ¨¡å‹åˆ†é¡ï¼‰
                if 'usage' in result:
                    usage = result['usage']
                    
                    # åˆå§‹åŒ–æ¨¡å‹çµ±è¨ˆ
                    if model_name not in self.token_usage['by_model']:
                        self.token_usage['by_model'][model_name] = {
                            'prompt_tokens': 0,
                            'completion_tokens': 0,
                            'total_tokens': 0,
                            'calls': 0
                        }
                    
                    # æ›´æ–°æ¨¡å‹çµ±è¨ˆ
                    self.token_usage['by_model'][model_name]['prompt_tokens'] += usage.get('prompt_tokens', 0)
                    self.token_usage['by_model'][model_name]['completion_tokens'] += usage.get('completion_tokens', 0)
                    self.token_usage['by_model'][model_name]['total_tokens'] += usage.get('total_tokens', 0)
                    self.token_usage['by_model'][model_name]['calls'] += 1
                    
                    # æ›´æ–°ç¸½è¨ˆ
                    self.token_usage['total']['prompt_tokens'] += usage.get('prompt_tokens', 0)
                    self.token_usage['total']['completion_tokens'] += usage.get('completion_tokens', 0)
                    self.token_usage['total']['total_tokens'] += usage.get('total_tokens', 0)
                    
                    print(f"   ğŸ’° Token ä½¿ç”¨: {usage.get('total_tokens', 0)} "
                          f"(Prompt: {usage.get('prompt_tokens', 0)}, "
                          f"Completion: {usage.get('completion_tokens', 0)})")
                
                print("   âœ… API èª¿ç”¨å®Œæˆ")
                
                return {
                    'content': result['choices'][0]['message']['content'],
                    'usage': result.get('usage', {}),
                    'model': model_name
                }
                
            except requests.exceptions.Timeout:
                print(f"   âš ï¸ è«‹æ±‚è¶…æ™‚ (å˜—è©¦ {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    time.sleep(5)
                    
            except requests.exceptions.RequestException as e:
                print(f"   âŒ API è«‹æ±‚å¤±æ•—: {e}")
                if attempt < max_retries - 1:
                    time.sleep(3)
                    
            except Exception as e:
                print(f"   âŒ æœªçŸ¥éŒ¯èª¤: {e}")
                break
        
        return None
    
    def _get_analysis_header(self, analysis_mode: str, has_news: bool, model_config: Dict) -> str:
        """ç²å–åˆ†ææ¨™é¡Œ"""
        
        mode_names = {
            'quick': 'âš¡ å¿«é€Ÿåˆ†æ',
            'comprehensive': 'ğŸ“Š å®Œæ•´åˆ†æ',
            'deep': 'ğŸ”¬ æ·±åº¦åˆ†æ'
        }
        
        mode_name = mode_names.get(analysis_mode, 'ğŸ“Š åˆ†æ')
        
        components = ['æŠ€è¡“é¢', 'ç±Œç¢¼é¢']
        if has_news:
            components.append('æ–°èé¢')
        
        header = f"## {mode_name}æ¨¡å¼ï¼ˆ{' + '.join(components)}ï¼‰\n"
        header += f"**ä½¿ç”¨æ¨¡å‹**: {model_config['model']}\n\n"
        
        return header
    
    def _get_fallback_news(self, symbol: str) -> Dict:
        """ç•¶ API å¤±æ•—æ™‚è¿”å›å‚™ç”¨æ–°èè¨Šæ¯"""
        return {
            'content': f"""## âš ï¸ æ–°èæœå°‹æš«æ™‚ç„¡æ³•ä½¿ç”¨

ç”±æ–¼ç¶²è·¯é€£ç·šå•é¡Œï¼Œç›®å‰ç„¡æ³•ç²å– {symbol} çš„æœ€æ–°æ–°èã€‚

### å»ºè­°æ›¿ä»£æ–¹æ¡ˆï¼š

1. **æ‰‹å‹•æŸ¥è©¢æ–°è**ï¼š
   - [é‰…äº¨ç¶²](https://news.cnyes.com/)
   - [ç¶“æ¿Ÿæ—¥å ±](https://money.udn.com/)
   - [å·¥å•†æ™‚å ±](https://ctee.com.tw/)
   - [Yahooå¥‡æ‘©è‚¡å¸‚](https://tw.stock.yahoo.com/)

2. **æŠ€è¡“é¢åˆ†æ**ï¼š
   - æœ¬ç³»çµ±çš„æŠ€è¡“æŒ‡æ¨™åˆ†æä»ç„¶å¯ç”¨
   - å»ºè­°åƒè€ƒ Kç·šåœ–å’Œäº¤æ˜“ä¿¡è™Ÿ

3. **ç¨å¾Œé‡è©¦**ï¼š
   - å‹¾é¸ã€Œå¼·åˆ¶å¾ API æ›´æ–°æ•¸æ“šã€å¾Œé‡æ–°åˆ†æ

---
**æç¤º**: ç•¶æ²–äº¤æ˜“å»ºè­°ä»¥æŠ€è¡“é¢ç‚ºä¸»ï¼Œæ–°èé¢ç‚ºè¼”
""",
            'is_fallback': True,
            'source': 'fallback',
            'model': 'fallback'
        }
    
    def _get_fallback_analysis(self, symbol: str, today_open: float, 
                               yesterday_close: float, latest_data) -> str:
        """ç•¶ AI åˆ†æå¤±æ•—æ™‚è¿”å›åŸºæœ¬åˆ†æ"""
        
        gap_percent = ((today_open - yesterday_close) / yesterday_close) * 100
        
        # è™•ç† Series æˆ– Dict
        if isinstance(latest_data, pd.Series):
            rsi = latest_data.get('RSI', 0)
            ma5 = latest_data.get('MA5', 0)
            ma20 = latest_data.get('MA20', 0)
            kd_k = latest_data.get('KD_K', 0)
        else:
            rsi = latest_data.get('RSI', 0) if latest_data else 0
            ma5 = latest_data.get('MA5', 0) if latest_data else 0
            ma20 = latest_data.get('MA20', 0) if latest_data else 0
            kd_k = latest_data.get('KD_K', 0) if latest_data else 0
        
        return f"""## âš ï¸ AI åˆ†ææš«æ™‚ç„¡æ³•ä½¿ç”¨

### åŸºæœ¬æŠ€è¡“åˆ†æ ({symbol})

#### åƒ¹æ ¼è³‡è¨Š
- æ˜¨æ—¥æ”¶ç›¤ï¼šNT$ {yesterday_close:.2f}
- ä»Šæ—¥é–‹ç›¤ï¼šNT$ {today_open:.2f}
- é–‹ç›¤ç¼ºå£ï¼š{gap_percent:+.2f}%

#### æŠ€è¡“æŒ‡æ¨™åƒè€ƒ
- RSIï¼š{rsi:.2f}
- MA5ï¼šNT$ {ma5:.2f}
- MA20ï¼šNT$ {ma20:.2f}
- KD_Kï¼š{kd_k:.2f}

### å»ºè­°
1. åƒè€ƒ K ç·šåœ–åˆ¤æ–·è¶¨å‹¢
2. æ³¨æ„æ”¯æ’å£“åŠ›ä½
3. åš´æ ¼åŸ·è¡Œåœæ
4. æ§åˆ¶éƒ¨ä½å¤§å°

### é¢¨éšªæç¤º
âš ï¸ ç•¶æ²–é¢¨éšªé«˜ï¼Œè«‹è¬¹æ…æ“ä½œ
âš ï¸ å»ºè­°ç­‰å¾… AI åˆ†ææ¢å¾©å¾Œå†é€²è¡Œäº¤æ˜“

---
**æ›¿ä»£æ–¹æ¡ˆ**ï¼šå‹¾é¸ã€Œå¼·åˆ¶æ›´æ–°ã€å¾Œé‡è©¦ï¼Œæˆ–ç¨å¾Œå†è©¦
"""
    
    def _get_token_info(self) -> str:
        """ç²å– Token ä½¿ç”¨çµ±è¨ˆ"""
        
        info = "---\n### ğŸ’° Token ä½¿ç”¨çµ±è¨ˆ\n\n"
        
        # ç¸½è¨ˆ
        total = self.token_usage['total']
        info += f"**ç¸½è¨ˆ**:\n"
        info += f"- Prompt Tokens: {total['prompt_tokens']:,}\n"
        info += f"- Completion Tokens: {total['completion_tokens']:,}\n"
        info += f"- Total Tokens: {total['total_tokens']:,}\n\n"
        
        # æŒ‰æ¨¡å‹åˆ†é¡
        if self.token_usage['by_model']:
            info += "**æŒ‰æ¨¡å‹åˆ†é¡**:\n"
            for model, usage in self.token_usage['by_model'].items():
                info += f"\n*{model}* ({usage['calls']} æ¬¡èª¿ç”¨):\n"
                info += f"- Total: {usage['total_tokens']:,} tokens\n"
        
        return info
    
    def _get_no_api_key_message(self) -> str:
        """è¿”å›ç„¡ API Key çš„è¨Šæ¯"""
        return """## âš ï¸ AI åˆ†æåŠŸèƒ½æœªå•Ÿç”¨

è«‹è¨­å®š `PERPLEXITY_API_KEY` ç’°å¢ƒè®Šæ•¸ä»¥ä½¿ç”¨ AI åˆ†æåŠŸèƒ½ã€‚

### è¨­å®šæ–¹å¼ï¼š
1. å‰å¾€ [Perplexity API](https://www.perplexity.ai/settings/api) å–å¾— API Key
2. åœ¨ `.env` æ–‡ä»¶ä¸­æ·»åŠ ï¼šPERPLEXITY_API_KEY=pplx-your-api-key-here
3. é‡æ–°å•Ÿå‹•ç¨‹å¼

### æ›¿ä»£æ–¹æ¡ˆï¼š
1. åƒè€ƒæŠ€è¡“æŒ‡æ¨™åˆ†æ
2. åƒè€ƒæ”¯æ’å£“åŠ›ä½
3. åƒè€ƒç±Œç¢¼æ•¸æ“š
4. æ‰‹å‹•é€²è¡Œäº¤æ˜“æ±ºç­–

---
**æç¤º**: æ‚¨ä»å¯ä»¥ä½¿ç”¨ç³»çµ±çš„æŠ€è¡“åˆ†æåŠŸèƒ½é€²è¡Œäº¤æ˜“æ±ºç­–
"""
 
    def _get_error_message(self, error: str) -> str:
     """è¿”å›éŒ¯èª¤è¨Šæ¯"""
     return f"""## âŒ AI åˆ†æå¤±æ•—
    
    éŒ¯èª¤è¨Šæ¯: {error}
    
    ### å»ºè­°ï¼š
    1. æª¢æŸ¥ PERPLEXITY_API_KEY æ˜¯å¦æ­£ç¢º
    2. ç¢ºèªç¶²è·¯é€£ç·šæ­£å¸¸
    3. åƒè€ƒæŠ€è¡“æŒ‡æ¨™æ‰‹å‹•åˆ†æ
    4. ç¨å¾Œé‡è©¦
    
    ---
    æ‚¨ä»å¯ä»¥ä½¿ç”¨ç³»çµ±çš„æŠ€è¡“åˆ†æåŠŸèƒ½é€²è¡Œäº¤æ˜“æ±ºç­–ã€‚
    """
     
    def get_token_usage(self) -> Dict:
     """ç²å– Token ä½¿ç”¨çµ±è¨ˆ"""
     return {
         'by_model': self.token_usage['by_model'].copy(),
         'total': self.token_usage['total'].copy()
     }
     
    def reset_token_usage(self):
     """é‡ç½® Token ä½¿ç”¨çµ±è¨ˆ"""
     self.token_usage = {
         'by_model': {},
         'total': {
             'prompt_tokens': 0,
             'completion_tokens': 0,
             'total_tokens': 0
         }
     }
     
    def print_token_report(self):
     """æ‰“å°è©³ç´°çš„ Token ä½¿ç”¨å ±å‘Š"""
     print("\n" + "="*60)
     print("ğŸ“Š Token ä½¿ç”¨å ±å‘Š")
     print("="*60)
     
     total = self.token_usage['total']
     print(f"\nç¸½è¨ˆ:")
     print(f"  Prompt Tokens:     {total['prompt_tokens']:>10,}")
     print(f"  Completion Tokens: {total['completion_tokens']:>10,}")
     print(f"  Total Tokens:      {total['total_tokens']:>10,}")
     
     if self.token_usage['by_model']:
         print(f"\næŒ‰æ¨¡å‹åˆ†é¡:")
         for model, usage in sorted(self.token_usage['by_model'].items()):
             print(f"\n  {model}:")
             print(f"    èª¿ç”¨æ¬¡æ•¸:   {usage['calls']:>3}")
             print(f"    Total:      {usage['total_tokens']:>10,} tokens")
             avg = usage['total_tokens']//usage['calls'] if usage['calls'] > 0 else 0
             print(f"    å¹³å‡æ¯æ¬¡:   {avg:>10,} tokens")
     
     print("\n" + "="*60 + "\n")


# ===== å‘å¾Œå…¼å®¹çš„å‡½æ•¸æ¥å£ =====

def search_news_events(symbol: str, api_key: str = None, force_update: bool = False, 
                   use_deep_research: bool = False) -> Dict:
 """å‘å¾Œå…¼å®¹çš„æ–°èæœå°‹å‡½æ•¸"""
 try:
     analyzer = AIAnalyzer(api_key)
     return analyzer.search_news_events(symbol, force_update, use_deep_research)
 except Exception as e:
     print(f"âŒ æ–°èæœå°‹éŒ¯èª¤: {e}")
     analyzer = AIAnalyzer(api_key)
     return analyzer._get_fallback_news(symbol)


def generate_daytrading_analysis(
 symbol: str,
 stock_data: pd.DataFrame,
 today_open: float,
 yesterday_close: float,
 support_resistance: Dict,
 institutional_data: Optional[pd.DataFrame] = None,
 news_events: Optional[Dict] = None,
 api_key: Optional[str] = None,
 analysis_mode: str = 'comprehensive',
 **kwargs
) -> str:
 """å‘å¾Œå…¼å®¹çš„åˆ†æç”Ÿæˆå‡½æ•¸"""
 try:
     if not api_key and not PERPLEXITY_API_KEY:
         return """## âš ï¸ AI åˆ†æåŠŸèƒ½æœªå•Ÿç”¨

è«‹è¨­å®š `PERPLEXITY_API_KEY` ç’°å¢ƒè®Šæ•¸ã€‚

### æ›¿ä»£æ–¹æ¡ˆï¼š
1. åƒè€ƒæŠ€è¡“æŒ‡æ¨™
2. åƒè€ƒæ”¯æ’å£“åŠ›ä½
3. æ‰‹å‹•æ±ºç­–

---
**æç¤º**: ç³»çµ±çš„æŠ€è¡“åˆ†æåŠŸèƒ½ä»å¯ä½¿ç”¨
"""
     
     analyzer = AIAnalyzer(api_key)
     result = analyzer.generate_daytrading_analysis(
         symbol, stock_data, today_open, yesterday_close,
         support_resistance, institutional_data, news_events,
         analysis_mode, **kwargs
     )
     
     # é¡¯ç¤º Token ä½¿ç”¨çµ±è¨ˆ
     usage = analyzer.get_token_usage()
     print(f"\nğŸ’° æœ¬æ¬¡åˆ†æ Token ç¸½æ¶ˆè€—: {usage['total']['total_tokens']:,}")
     
     return result
     
 except Exception as e:
     print(f"âŒ åˆ†æç”ŸæˆéŒ¯èª¤: {e}")
     return f"âŒ åˆ†æå¤±æ•—: {str(e)}"


# ===== ä¸»ç¨‹å¼æ¸¬è©¦ =====

if __name__ == "__main__":
 # æ¸¬è©¦
 api_key = os.getenv("PERPLEXITY_API_KEY")
 
 if api_key:
     try:
         analyzer = AIAnalyzer(api_key)
         
         print("=" * 60)
         print("ğŸ§ª æ¸¬è©¦ AI åˆ†ææ¨¡çµ„ï¼ˆå¤šæ¨¡å‹å„ªåŒ–ç‰ˆï¼‰")
         print("=" * 60)
         
         # æ¸¬è©¦æ–°èæœå°‹ï¼ˆä¸€èˆ¬æ¨¡å¼ï¼‰
         print("\n1ï¸âƒ£ æ¸¬è©¦ä¸€èˆ¬æ–°èæœå°‹...")
         news = analyzer.search_news_events("2330", force_update=True)
         print(f"   ä¾†æº: {news['source']}")
         print(f"   æ¨¡å‹: {news.get('model', 'N/A')}")
         print(f"   å…§å®¹é è¦½: {news['content'][:150]}...")
         
         # æ¸¬è©¦æ–°èæœå°‹ï¼ˆæ·±åº¦ç ”ç©¶æ¨¡å¼ï¼‰
         print("\n2ï¸âƒ£ æ¸¬è©¦æ·±åº¦ç ”ç©¶æ¨¡å¼...")
         deep_news = analyzer.search_news_events("2330", force_update=True, use_deep_research=True)
         print(f"   ä¾†æº: {deep_news['source']}")
         print(f"   æ¨¡å‹: {deep_news.get('model', 'N/A')}")
         print(f"   å…§å®¹é è¦½: {deep_news['content'][:150]}...")
         
         # é¡¯ç¤º Token ä½¿ç”¨å ±å‘Š
         analyzer.print_token_report()
         
         print("\nâœ… æ¸¬è©¦å®Œæˆ")
         
     except Exception as e:
         print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
         import traceback
         print(traceback.format_exc())
 else:
     print("âŒ è«‹è¨­å®š PERPLEXITY_API_KEY ç’°å¢ƒè®Šæ•¸")

